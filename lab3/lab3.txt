ТЕОРЕТИЧЕСКАЯ ЧАСТЬ

1. Фреймворк Caffe

1.1. Что такое Caffe
Caffe – один из главных инструментов, применяющихся сегодня для решения задач распознавания визуальных и аудио-образов, в том числе речи. Разработан Центром распознаваний образов и машинного обучения университета Беркли (Berkeley Visionand Learning Center).
Весь код библиотеки Caffe является открытым, написан на языке C++, а сам продукт полностью поддерживает написание пользовательских алгоритмов на Python/NumPy, а также совместим с MATLAB.
Caffe предлагает широкий инструментарий для создания и применения современных алгоритмов глубокого обучения.

1.2. Принципы работы
Библиотека хранит данные в четырехмерных массивах, называемых блобами (blob), которые предоставляют интерфейс для хранения серий изображений (или других файлов), их параметров и данных об обновлении этих параметров.
Поскольку операции над этими данными происходят посредством взаимодействия процессора и графического процессора, что налагает определенные ограничения на скорость их обработки, Caffe позволяет снизить временные затраты посредством синхронизации работы устройств «по требованию» (Unified Memory Model).
Это означает, что центральный процессор передает данные графическому устройству только после того, как произойдет запрос к этим данным, причем «вспомогательные» параметры нижних слоев архитектуры (блоба) игнорируются. Таким образом достигается приличная скорость работы системы, что немаловажно в случае глубоких архитектур с большим количеством уровней информации. Кроме того, это очевидно позволяет существенно повысить эффективность использования памяти компьютера.

1.3. Архитектура нейронной сети
Если в алгоритмах машинного обучения необходимо было формировать хороший вектор признаков, чтобы получить приемлемое качество, то в сверточных нейросетях этого делать не нужно. Главное – придумать хорошую архитектуру сети.
В архитектуре сети используются следующие слои:
• input – входной слой, обычно это пиксели изображения,
• conv – слой свертки,
• pool – слой подвыборки,
• fully-conn – полносвязный слой,
• output – выходной слой, выдает предполагаемый класс изображения.

Для задачи классификации изображений основной является следующая архитектура:
input -> conv -> pool -> conv -> pool -> fully-conn -> fully-conn -> output
Количество (conv -> pool) слоев может быть разным, но обычно не меньше 2х. Количество fully-conn не меньше 1го.
Подробное описание слоев Caffe: http://caffe.berkeleyvision.org/tutorial/layers.html.

2. Классификация изображений ImageNet

2.1. Пути к данным. Data-файлы
Для дальнейшего обучения и проверки нейронной сети потребуются исходные размеченные данные. В качестве таких данных будет использоваться ImageNet. Изображения с ImageNet – база данных изображений, организованная в соответствии с иерархией WordNet. Данные ImageNet для обучения и проверки задач классификации уже загружены и находятся в директории:
• Пример пути изображения для обучения (папка train):
/home/image-net/ILSVRC2015/Data/CLS-LOC/train/n01440764/n01440764_10026.JPEG
• Пример пути изображения для проверки (папка val):
/home/image-net/ILSVRC2015/Data/CLS-LOC/val/ILSVRC2012_val_00000001.JPEG

Входные данные для обучения и тренировки представлены в виде списка, где указан путь изображения и номер класса от 0 до 999.

Пример данных /home/caffe/data/ilsvrc12/train.txt:
n01440764/n01440764_10026.JPEG 0
n01440764/n01440764_10027.JPEG 0
n01440764/n01440764_10029.JPEG 0
…
n15075141/n15075141_9942.JPEG 999
n15075141/n15075141_999.JPEG 999
n15075141/n15075141_9993.JPEG 999

Пример данных /home/caffe/data/ilsvrc12/val.txt:
LSVRC2012_val_00000001.JPEG 65
ILSVRC2012_val_00000002.JPEG 970
ILSVRC2012_val_00000003.JPEG 230
…
ILSVRC2012_val_00049998.JPEG 232
ILSVRC2012_val_00049999.JPEG 982
ILSVRC2012_val_00050000.JPEG 355

Описание класса с номером от 0 до 999 соответствует с номеру строки в файле /home/caffe/data/ilsvrc12/synset_words.txt:
01440764 tench, Tinca tinca
n01443537 goldfish, Carassius auratus
…
n13133613 ear, spike, capitulum
n15075141 toilet tissue, toilet paper, bathroom tissue

При работе с большим набором данных Caffe использует формат LMDB. Чтобы создать базу изображений в формате LMDB можно воспользоваться скриптом /home/caffe/examples/imagenet/create_imagenet.sh. В нем указываются директории изображений ImageNet для обучения и проверки (TRAIN_DATA_ROOT, VAL_DATA_ROOT), а номера классов изображений берутся из файлов train.txt и val.txt директории DATA=data/ilsvrc12. Если изображения не были изменены заранее, то устанавливается RESIZE=true, чтобы изменить размер изображения до 256x256.
После завершения работы скрипта будут созданы 2 директории: ilsvrc12_train_lmdb и ilsvrc12_val_lmdb. Эти директории не должны существовать до момента запуска!
Для проведения расчетов при обучении модели требуется вычесть среднее значение из каждого изображения, поэтому сначала мы должны вычислить среднее значение.
Запуск вычисления запускается скриптом:
/home/caffe/examples/imagenet/make_imagenet_mean.sh.
Данный скрипт создаст файл imagenet_mean.binaryproto.

2.2. Определение модели обучения
Определение архитектуры модели нейронной сети, описанной Крижевским, находится в файле /home/caffe/models/bvlc_reference_caffenet/train_val.prototxt.
В модели сети указаны 2 стадии: обучение(TRAIN) и проверка(TEST). Эти разделы позволяют определить две тесно связанные между собой сети в одном файле: сеть, используемая для обучения и сеть, используемая для тестирования. Эти две сети практически идентичны и отличаются обозначением поля include: include { phase: TRAIN } или include { phase: TEST }.
Различие входных слоев:
• Слой data для обучения сети имеет путь к базе LMDB: examples/imagenet/ilsvrc12_train_lmdb.
• Слой data для проверки сети имеет путь к базе LMDB: examples/imagenet/ilsvrc12_val_lmdb.
Получить изображение структуры сети можно с помощью draw_net.py:
«python /home/caffe/python/draw_net.py /home/caffe/models/bvlc_reference_caffenet/deploy.prototxt image.png --rankdir TB»
Или с помощью http://ethereon.github.io/netscope/#/editor

Различия выходных слоев: Выходной слой соединяется со слоем функцией потерь (type: softmax_loss) и слоем точности (type: accuracy). Слой точности срабатывает только в тестовой фазе и показывает процент верно классифицированных изображений в валидационной тестовой выборке.

Чтобы приступить к обучению сети, необходимо настроить параметры обучения. Они находятся в описании солвера в фале /home/caffe/models/bvlc_reference_caffenet/solver.prototxt. Эти параметры помогают выстроить план обучения и проверки модели сети, в нашем случае:

• net: "models/bvlc_reference_caffenet/train_val.prototxt" – указание пути до архитектуры модели нейронной сети.
• max_iter: 450000 – общее количество итераций 450 000.
• test_iter: 1000 - сколько итераций тестирования необходимо делать.
• test_interval: 1000 – после каждой 1000-й итерации обучения проводится тестирование на проверочных данных.
• base_lr: 0.01 – начальная скорость обучения равна 0.01.
• lr_policy: "step" - уменьшение скорости обучения, каждый step.
• gamma: 0.1 -  на сколько уменьшать скорость обучения.
• stepsize: 100000 – уменьшение скорости обучения каждые 100 000  итераций.
• display: 20 – печать информации через каждые 20 итераций.
• momentum: 0.9 – импульс обучения 0.9.
• weight_decay: 0.0005 – вес распада 0.0005.
• snapshot: 10000 – каждые 10 000 итераций сохраняется текущее состояние в файл.
• snapshot_prefix: "models/bvlc_reference_caffenet/caffenet_train" – префикс сохраняемых файлов.
• solver_mode: GPU – выполнить решение с помощью видеокарты.
Подробнее: http://caffe.berkeleyvision.org/tutorial/solver.html.

2.3. Запуск обучения сети
Запуск обучения выполняется скриптом /home/caffe/examples/imagenet/train_caffenet.sh. Данный скрипт содержит:
./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt
Запуск скрипта в фоновом режиме (вывод):
nohup ./examples/imagenet/train_caffenet.sh 1>out_train.txt &

2.4. Возобновление обучения сети
Чтобы начать обучение с сохраненного ранее состояния нужно запустить обучение с параметром --snapshot и указать файл состояния обучения сети:
./build/tools/caffe train --solver=models/bvlc_reference_caffenet/solver.prototxt
 --snapshot=models/bvlc_reference_caffenet/caffenet_train_iter_10000.solverstate»

ПРАКТИЧЕСКАЯ ЧАСТЬ

3. Использование обученной сверточной сети для классификации базы изображений ImageNet
Необходимые материалы для выполнения лабораторной работы находятся в директории (labs/lab3).

3.1. Код для классификации на готовой модели
В этом примере показана классификация изображения с помощью готовой модели CaffeNet, которая основана на архитектуре сети Крижевского (Krizhevsky) для ImageNet.
Мы будем использовать нейронную сеть, основанную на архитектуре Крижевского (Krizhevsky) и его команды, позволившей им выиграть соревнование ImageNet 2012. Сеть уже обучена командой BVLC, но поскольку обучение происходило на наборе изображений, доступном только для некоммерческого использования, она также может применяться только в исследовательских целях. Данная сеть способна распознавать 1 000 различных категорий объектов.
Готовая модель сохранена на 310 000 итерации. Лучшая лучший результат проверки был во время обучения на 313 000 итерации с точностью 57.412% и потерей 1.82328. Эта модель получила топ-1 точность 57.4% и топ-5 точность 80.4% на проверочном наборе данных. Подробнее: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf

Краткое описание кода классификации classification.py:
1. Настройка. Добавление необходимых модулей, путей и файлов.
2. Загрузка сети.  Настройка преобразователя входного изображения.
3. Классификация тестового изображения. Сравнение времени выполнения в режимах CPU и GPU.
4. Изучение промежуточных результатов классификации. Вывод формы и параметров слоев.
5. Вспомогательная функция визуализации фильтров слоев.
6. Классификация собственного изображения.

3.2. Задачи для готовой модели
В отчете нужно представить:
1) Сравнение времени выполнения классификации в режимах CPU и GPU. Ускорение на GPU. Результаты усреднять по 10 измерениям.
2) Получить ТОП-5 вероятностей совпадения для тестового изображения.
3) Показать фильтры сети и классифицируемое изображение после прохождение через эти фильтры.
4) Привести результаты классификации своего изображения.
5) Показать изображение после прохождения через фильтры сети.

НЕОБЯЗАТЕЛЬНАЯ ПРАКТИЧЕСКАЯ ЧАСТЬ

3.3. Собственная модель
Разработать и обучить модель сверточной нейронной сети для классификации изображений трех классов - кошки, собаки, совы.
Требуется добиться быстрого обучения сети с приемлемым результатом классификации.

В отчете необходимо:
1) Изобразить используемую архитектуру сети, привести листинг архитектуры.
2) Перечислить параметры солвера.
3) Представить графики loss и accuracy во время обучения.
4) Сравнить результаты своей модели и готовой модели Крижевского.
5) Представить фильтры сети и изображения после прохождение через фильтры.

Вспомогательные файлы в папке labs/lab3/optional:
- binaryproto_to_npy_mean.py - конвертирует mean lmdb файл в numpy array
- lmdb_reader.py - читаетlmdb файл
- prepare_data_own_LMDB.txt - скрипты для подготовки lmdb файла